{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Case Study - San Jose, CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to OpenStreetMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the organization's *(openstreetmap.org)* website, OpenStreetMap is built by a community of mappers that contribute and maintain data about roads, trails, cafés, railway stations, and much more, all over the world. It is free to use under an open license. \n",
    "<br>\n",
    "<br>\n",
    "** My chose map area **: San Jose, California, United States \n",
    "https://www.openstreetmap.org/relation/112143\n",
    "<br>Data is downloaded as an OSM XML file from:\n",
    "https://mapzen.com/data/metro-extracts/metro/san-jose_california/\n",
    "<br><br>\n",
    "I am interested in exploring this area, because it is very close to where I live and I am familiar with street names and amenities around San Jose. I would also like to complete this project by providing insights to further improve the consistency and validity of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems encountered in map - Data audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running auditing.py to check for the correct address formatting, the main areas for improvement are: \n",
    "\n",
    "** Unusual / Unrecognizable Street Names **\n",
    "<ul><li> Abbreviated street names ('Wolfe Rd', 'Berryessa Rd')</li>\n",
    "    <li> Missing the street type from the end. ('North 23rd', 'South 25th')</li>\n",
    "    <li> House number, or apt number entered into the wrong space when data was filled out. ('Southeast 132nd Street #1', 'Northwest Byron Street #100')</li>\n",
    "    <li> Invalid values. ('yes', '?', etc.)</li>\n",
    "    <li> Apartment complex's name is entered instead of valid street address. ('Portofino', 'Seville', etc.)</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviated street names are cleaned systematically with iterative parsing in auditing.py in order to make the data formatting more consistent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wolfe Rd => Wolfe Road\n",
      "Mt Hamilton Rd => Mt Hamilton Road\n",
      "Berryessa Rd => Berryessa Road\n",
      "Saratoga Los Gatos Rd => Saratoga Los Gatos Road\n",
      "Quimby Rd => Quimby Road\n",
      "San Antonio Valley Rd => San Antonio Valley Road\n",
      "Homestead Rd => Homestead Road\n",
      "Mt. Hamilton Rd => Mt. Hamilton Road\n",
      "Silver Creek Valley Rd => Silver Creek Valley Road\n",
      "wilcox ave => wilcox Avenue\n",
      "Cortona court => Cortona Court\n",
      "Monterey Hwy => Monterey Highway\n",
      "Fountain Oaks Dr => Fountain Oaks Drive\n",
      "Minto Dr => Minto Drive\n",
      "1350 S Park Victoria Dr => 1350 S Park Victoria Drive\n",
      "Linwood Dr => Linwood Drive\n",
      "1490 S Park Victoria Dr => 1490 S Park Victoria Drive\n",
      "Samaritan Dr => Samaritan Drive\n",
      "Evergreen Village Sq => Evergreen Village Square\n",
      "N 5th St => N 5th Street\n",
      "Monroe St => Monroe Street\n",
      "Casa Verde St => Casa Verde Street\n",
      "Celadon Cir => Celadon Circle\n",
      "Los Gatos Boulvevard => Los Gatos Boulevard\n",
      "N 1st street => N 1st Street\n",
      "Los Gatos Blvd => Los Gatos Boulevard\n",
      "Mission College Blvd => Mission College Boulevard\n",
      "Stevens Creek Blvd => Stevens Creek Boulevard\n",
      "Santa Teresa Blvd => Santa Teresa Boulevard\n",
      "Palm Valley Blvd => Palm Valley Boulevard\n",
      "N McCarthy Blvd => N McCarthy Boulevard\n",
      "Cherry Ave => Cherry Avenue\n",
      "Saratoga Ave => Saratoga Avenue\n",
      "Greenbriar Ave => Greenbriar Avenue\n",
      "Blake Ave => Blake Avenue\n",
      "Foxworthy Ave => Foxworthy Avenue\n",
      "N Blaney Ave => N Blaney Avenue\n",
      "Meridian Ave => Meridian Avenue\n",
      "Westfield Ave => Westfield Avenue\n",
      "The Alameda Ave => The Alameda Avenue\n",
      "Seaboard Ave => Seaboard Avenue\n",
      "Walsh Ave => Walsh Avenue\n",
      "E Duane Ave => E Duane Avenue\n",
      "W Washington Ave => W Washington Avenue\n",
      "1425 E Dunne Ave => 1425 E Dunne Avenue\n",
      "Cabrillo Ave => Cabrillo Avenue\n",
      "Hollenbeck Ave => Hollenbeck Avenue\n",
      "Los Gatos Blvd. => Los Gatos Boulevard\n",
      "Perivale Ct => Perivale Court\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "osmfile = \"san_jose_california.osm\"\n",
    "\n",
    "#unusual street types\n",
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "street_types = defaultdict(set)\n",
    "\n",
    "#expected values based on current usps database\n",
    "expected_street = [\"Close\", \"Cove\", \"Commons\", \"Bend\", \"Grove\", \"Green\", \"Glen\",\n",
    "            \"Gardens\", \"Heights\", \"Highway\", \"Hills\", \"Landing\", \"Mall\",\n",
    "            \"Meadows\", \"Park\", \"Parkway\", \"Plaza\", \"Point\", \"Ridge\", \"Row\",\n",
    "            \"Run\", \"Spur\", \"Square\", \"Station\", \"Terrace\", \"Trail\", \"View\",\n",
    "            \"Vista\", \"Walk\", \"Wall\", \"Alley\", \"Center\", \"Crescent\", \"Way\",\n",
    "            \"Road\", \"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\",\n",
    "            \"Place\", \"Alley\", \"Circle\", \"Estates\", \"Lane\", \"Loop\", \"Expressway\"]\n",
    "\n",
    "#corrections\n",
    "mapping = { \"street\": \"Street\",\n",
    "            \"st\": \"Street\",\n",
    "            \"boulevard\" : \"Boulevard\",\n",
    "            \"avenue\": \"Avenue\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"av.\": \"Avenue\",\n",
    "            \"Ter\": \"Terrace\",\n",
    "            \"Steet\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"St\": \"Street\",\n",
    "            \"street\": \"Street\",\n",
    "            \"Pkwy\": \"Parkway\",\n",
    "            \"ST\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"ROAD\": \"Road\",\n",
    "            \"RD\": \"Road\",\n",
    "            \"Pl\": \"Plaza\",\n",
    "            \"PL\": \"Plaza\",\n",
    "            \"Ln.\": \"Lane\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"CT\": \"Court\",\n",
    "            \"court\": \"Court\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Boulvevard\": \"Boulevard\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Av.\": \"Avenue\",\n",
    "            \"AVENUE\": \"Avenue\",\n",
    "            \"AVE\": \"Avenue\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Sq\": \"Square\"\n",
    "           }\n",
    "\n",
    "\n",
    "#checks if values are in the expected_street names list\n",
    "#and adds them to the street types dict if not \n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected_street:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "#helper function used in audit(osmfile), to use correct element\n",
    "def is_street_name(tag):\n",
    "    return (tag.attrib['k'] == \"addr:street\")\n",
    "\n",
    "#checks steet types for node and way top level tags\n",
    "#prints out the unusual street types in a dictionary format - if needed remove #\n",
    "#returns the unusual street types\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    #pprint.pprint(dict(street_types))                \n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "#Cleaning the data by replacing the unusual street types with the corrections in mapping\n",
    "#prints out the cleaned data\n",
    "def fix_street(osmfile):\n",
    "    st_types = audit(osmfile)\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            if st_type in mapping:\n",
    "                better_name = name.replace(st_type, mapping[st_type])\n",
    "                print name, \"=>\", better_name\n",
    "                \n",
    "fix_street(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** City Names in the OSM file ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities in the OSM file: set(['cupertino', 'Sunnyvale, CA', 'Santa Clara', 'Moffett Field', 'Felton', 'campbell', 'Los Gato', 'Milpitas', 'Mountain View', 'Fremont', 'Campbelll', 'Coyote', 'SUnnyvale', u'San Jos\\xe9', 'Saratoga', 'Los Gatos, CA', 'Sunnyvale', 'Alviso', 'Mt Hamilton', 'Santa clara', 'Cupertino', 'los gatos', 'santa clara', 'santa Clara', 'Morgan Hill', 'Los Gatos', 'sunnyvale', 'Campbell', 'Redwood Estates'])\n"
     ]
    }
   ],
   "source": [
    "#checks what cities are present in this OSM file\n",
    "def audit_city(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")  \n",
    "    cities = set()\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == \"addr:city\" and tag.attrib['v'] != \"San Jose\" and tag.attrib['v'] != \"san Jose\" and tag.attrib['v'] != \"San jose\" and tag.attrib['v'] != \"san jose\":\n",
    "                    cities.add(tag.attrib['v'])\n",
    "    print \"Cities in the OSM file:\", cities\n",
    "    \n",
    "audit_city(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Incorrect Postal Zipcodes **\n",
    "\n",
    "Next, we take a look at the postal codes in the OSM file. To account for the inconsistency and filter out the invalid zipcodes, iterative parsing of elements is being used in auditing.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected_zipcode = [\"94089\", \"95002\", \"95008\", \"95013\", \"95014\", \"95032\",\n",
    "                     \"95035\", \"95037\", \"95050\", \"95054\", \"95070\", \"95110\",\n",
    "                     \"95111\", \"95112\", \"95113\", \"95116\", \"95117\", \"95118\",\n",
    "                     \"95119\", \"95120\", \"95121\", \"95122\", \"95123\", \"95124\",\n",
    "                     \"95125\", \"95126\", \"95127\", \"95128\", \"95129\", \"95130\",\n",
    "                     \"95131\", \"95132\", \"95133\", \"95134\", \"95135\", \"95136\",\n",
    "                     \"95138\", \"95139\", \"95140\", \"95148\"] \n",
    "\n",
    "invalid_zipcodes = defaultdict(set)\n",
    "\n",
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    digits = zipcode[0:6]\n",
    "    if digits not in expected_zipcode:\n",
    "        invalid_zipcodes[digits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(tag):\n",
    "    return (tag.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes, tag.attrib['v'])\n",
    "    #pprint.pprint(dict(invalid_zipcodes))\n",
    "    osm_file.close()\n",
    "    return invalid_zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the audit above, there are zipcodes that have a formatting of xxxxx-xxxx (10 characters). To make the data more consistent only the first 5 numbers will be retained. Also, we have an invalid zipcode (951251) which has a typo and cannot be corrected with certainty. In this case and when the corrections cannot be completed with certainty, we will replace the incorrect value with \"None\". Also, some zipcodes start with 'CA'. These zipcodes will be cleaned by removing the letters. \n",
    "\n",
    "Some examples, in which the data was cleaned by the previous outline:\n",
    "\n",
    "1. CA 95116 => 95116\n",
    "2. set(['95191'])\n",
    "3. 951251 => None\n",
    "4. 95112-5005 => 95112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tags with Problematic Character **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 'service area', 'v': '20 miles'}\n",
      "{'problemchars': 1, 'lower': 482276, 'other': 22335, 'lower_colon': 231485}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# check the \"k\" value for each \"<tag>\"\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            if lower.search(tag.attrib['k']):\n",
    "                keys['lower'] += 1\n",
    "            elif lower_colon.search(tag.attrib['k']):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif problemchars.search(tag.attrib['k']):\n",
    "                print tag.attrib\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(osmfile):\n",
    "    keys = {\"lower\": 0, \n",
    "            \"lower_colon\": 0, \n",
    "            \"problemchars\": 0, \n",
    "            \"other\": 0}\n",
    "    for _, element in ET.iterparse(osmfile):\n",
    "        keys = key_type(element, keys)\n",
    "    print keys\n",
    "\n",
    "process_map(osmfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is only one problematic character in the OSM file. \n",
    "<br><br>\n",
    "** The above characteristics can be described as follows: **\n",
    "<ol><li> \"lower\" : 482276, tags containing only lowercase letters and are valid </li>\n",
    "<li>\"lower_colon\" : 231485, valid tags with a colon in their names </li>\n",
    "<li>\"problemchars\" : 1, tags with problematic characters </li>\n",
    "<li>\"other\" : 22335, other tags that do not fall into the other three categories </li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File size and type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running auditing.py and the unusual street names are removed, I am going to transform the values first into their respective CSV files based on the tags (transforming.py) and then into a SQL database (insert_into_database.py). \n",
    "<br><br>The details of the files are the following:\n",
    "\n",
    "**san_jose_california.osm**: 380,743,544 bytes (380.7 MB)<br>\n",
    "**san_jose_california.db**: 266,190,848 bytes (266.2 MB)<br>\n",
    "**nodes_tags.csv**: 3,109,747 bytes (3.1 MB)<br>\n",
    "**nodes.csv**: 146,479,470 bytes (146.5 MB) <br>\n",
    "**ways_nodes.csv**: 48,711,778 bytes (48.7 MB)<br>\n",
    "**ways_tags.csv**: 22,170,698 bytes (22.2 MB)<br>\n",
    "**ways.csv**: 14,018,735 bytes (14 MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the OSM XML file consists of elements:\n",
    "<li>nodes: points in space, along with at least one id number and a coordinate</li>\n",
    "<li>ways: ordered lists of nodes that define a polyline, such as linear features and area boundaries</li>\n",
    "<li>relations: which may or may not be used used to explain how other elements work together</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a general idea about the number of times certain tags can be encountered, iterative parsing was used on the map file. The function below returns a dictionary with the tag name as the key and the number of times this tag is found in the OSM file as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 20014,\n",
      " 'nd': 2045744,\n",
      " 'node': 1752581,\n",
      " 'osm': 1,\n",
      " 'relation': 2083,\n",
      " 'tag': 736097,\n",
      " 'way': 235451}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "filename = 'san_jose_california.osm'\n",
    "\n",
    "def count_tags(filename):\n",
    "    data = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag in data.keys():\n",
    "            data[element.tag] += 1\n",
    "        else:\n",
    "            data[element.tag] = 1\n",
    "    pprint.pprint(data)\n",
    "    \n",
    "count_tags(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT COUNT(*) FROM nodes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1752581"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT COUNT(*) FROM ways;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "235451"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407\n"
     ]
    }
   ],
   "source": [
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get(\"uid\"):\n",
    "            users.add(element.attrib[\"uid\"])\n",
    "    print len(users)\n",
    "\n",
    "process_map(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1407 unique users in the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities in the OSM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT tags.value, COUNT(*) as count \n",
    "        FROM (SELECT * FROM nodes_tags \n",
    "              UNION ALL \n",
    "              SELECT * FROM ways_tags) tags\n",
    "        WHERE tags.key == 'city' \n",
    "        GROUP BY tags.value \n",
    "        ORDER BY count DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sunnyvale|3421\n",
    "San Jose|1042\n",
    "Morgan Hill|397\n",
    "Santa Clara|323\n",
    "Saratoga|233\n",
    "San José|174\n",
    "Los Gatos|138\n",
    "Milpitas|105\n",
    "Campbell|76\n",
    "Cupertino|61\n",
    "Alviso|11\n",
    "Mountain View|7\n",
    "san jose|6\n",
    "Campbelll|3\n",
    "sunnyvale|3\n",
    "san Jose|2\n",
    "santa Clara|2\n",
    "Coyote|1\n",
    "Felton|1\n",
    "Fremont|1\n",
    "Los Gato|1\n",
    "Los Gatos, CA|1\n",
    "Moffett Field|1\n",
    "Mt Hamilton|1\n",
    "Redwood Estates|1\n",
    "SUnnyvale|1\n",
    "San jose|1\n",
    "Santa clara|1\n",
    "Sunnyvale, CA|1\n",
    "campbell|1\n",
    "cupertino|1\n",
    "los gatos|1\n",
    "santa clara|1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the findings, most of the addresses are from Sunnyvale. This confirms my suspicion that it would be more appropriate to name the map area as San Jose and its victinity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT value, COUNT(*) as count\n",
    "        FROM nodes_tags \n",
    "        WHERE nodes_tags.key = 'cuisine'\n",
    "        GROUP BY value\n",
    "        ORDER BY count DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vietnamese|118\n",
    "mexican|114\n",
    "sandwich|96\n",
    "pizza|91\n",
    "chinese|88\n",
    "coffee_shop|76\n",
    "japanese|47\n",
    "indian|46\n",
    "burger|42\n",
    "american|39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this query, I have noticed that on the bottom of this list there are some cuisines misspelled or containing typos, which makes the results a little bit skewed. There are a couple of results where the cuisine is not clearly determined and contains a list of the type of foods that can be bought at the place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT COUNT(*) AS num\n",
    "        FROM nodes_tags\n",
    "        WHERE nodes_tags.value = 'school';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query revealed that there are 149 schools in the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT value, count(*) as num FROM nodes_tags\n",
    "        WHERE key='amenity'\n",
    "        GROUP BY value\n",
    "        ORDER BY num DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restaurant|884\n",
    "fast_food|422\n",
    "bench|313\n",
    "cafe|257\n",
    "bicycle_parking|202\n",
    "place_of_worship|171\n",
    "toilets|160\n",
    "school|143\n",
    "bank|130\n",
    "parking_space|128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, restaurant is the top amenity, followed by fast food and bench. Bench in this context, I assume, refers to parks and BBQ area; although this could be elaborated on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings and Ideas about the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was audited and the abbreviated street names were cleaned as applicable, however, the consistency of the dataset could be further improved and a periodic audits would also be beneficial. It is interesting to see how many misspellings and typos exist and probably affect the outcome of some research that may be done on this dataset. The map can be beneficial for small-scale applications, such as finding amenities, however, there is a lot to be done to improve its accuracy if the intention is to grow.\n",
    "<br><br>It is certainly a challenge to ensure that all the data being entered into the map area is valid, does not have any typos, and are entered into the correct place. Human error cannot be eliminated completely, however, certain measures could help. For example, preventing multiple entry of data into one field at a time can be achieved with restricting characters such as colon (:), semicolon (;), or comma (,) where it is applicable. Although, the wiki.openstreetmap.org website does offer some guidance for editing, after querying some fields I still have the sense that this is not being monitored closely. Also, at some fields, such as amenities; multiple choice selections or a list of options would help to categorize data.<br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. OpenStreetMap website, https://www.openstreetmap.org/about.\n",
    "2. OSM file formats, OpenStreetMap Wikia website http://wiki.openstreetmap.org/wiki/OSM_file_formats\n",
    "3. Udacity's Data Analyst Nanodegree track - Data Wrangling https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075461/lessons/5436095827/concepts/8063289030923\n",
    "4. USPS street names and suffixes, http://pe.usps.gov/text/pub28/28apc_002.htm\n",
    "5. Zip code data. http://www.city-data.com/zipmaps/San-Jose-California.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
